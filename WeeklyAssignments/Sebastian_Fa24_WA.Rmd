---
title: "D2SC: Weekly Assignments"
output: html_notebook
author: "Albert Sebastian"
date: 'r Sys.Date()'
---

# Initial Loading

```{r}
library(tidyverse)
library(ggdist)
```


# Weekly Assignment 1

To figure out how to load a package in R, I started by searching for "how to load an R package" in Google. I found several helpful resources, including Stack Overflow and the RStudio website. One useful link was 'Stack Overflow - How to Load a Package in R' (https://stackoverflow.com/questions/11805142/how-to-load-a-package-in-r). 

I verified that the 'tidyverse' package was correctly loaded by running 'library(tidyverse)' in the R console and checking that no error messages appeared. I also used the 'sessionInfo()' function to confirm that 'tidyverse' was listed among the loaded packages.

```{r}
help(package = "tidyverse")
```

The 'tidyverse' is a set of packages that work in harmony because they share common data representations and 'API' design. This package is designed to make it easy to install and load multiple 'tidyverse' packages in a single step. Learn more about the 'tidyverse' at https://www.tidyverse.org.


# Weekly Assignment 2

```{r}
library(readr)
analogy_data <- read_csv("\\Users\\alber\\Documents\\GitHub\\CogSci412-Data2SciComm\\WeeklyAssignments\\WeeklyAssignments\\tidy_data\\MFIndD_analogy.csv")
analogy_data

```
The qualtrics_id column seems to be the unique identifier for each participant

```{r}
library(dplyr)

dimensions <- dim(analogy_data)
rows <- dimensions[1]
cols <- dimensions[2]
rows
cols
```
2a. There are 792 rows and 6 columns in the dataset. The dim() function was used to retrieve the dimensions of the dataset, specifically the number of rows and columns. By calling dim(analogy_data), it returned a vector where the first element indicated the number of rows and the second element indicated the number of columns.
```{r}
unique_participants <- analogy_data %>%
  distinct(qualtrics_id) %>%
  count()
unique_participants
```
There are 99 unique people in the dataset.
```{r}
trials_per_participant <- analogy_data %>%
  group_by(qualtrics_id) %>%
  summarise(trial_count = n())

consistent_trials <- n_distinct(trials_per_participant$trial_count) == 1
consistent_trials
```
Everyone has the same number of trials in this dataset

# Weekly Assignment 3
```{r, eval=FALSE}
# Attempting to summarize relational matches
summary_data <- analogy_data %>%
  group_by(participant_id) %>%
  summarize(relational_matches = sum(response_type == "Relational", na.rm = TRUE))
```

In this chunk, I mistakenly used "Relational" as the condition in the 'sum()' function instead of "Rel." As a result, the summarization returned 'NA' values because there were no matches found for that string in the 'response_type' column. 

To fix it, I:
1. Reviewed the dataset to check the exact labels used for the responses.
2. Realized that the correct label was `"Rel"` for relational matches.
3. Updated the code accordingly:

```{r}
# Summarize the data
summary_data <- analogy_data %>%
  group_by(qualtrics_id) %>%
  summarize(relational_matches = sum(response_type == "Rel", na.rm = TRUE))

# Check the result
head(summary_data)
```

```{r}
library(ggplot2)

# Create a histogram
ggplot(summary_data, aes(x = relational_matches)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Distribution of Relational Matches",
       x = "Number of Relational Matches",
       y = "Frequency") +
  theme_minimal()
```
The histogram shows a right-skewed distribution, with most participants selecting a low number of relational matches, and a few participants achieving higher counts.This indicates that the majority of participants may struggle with recognizing relational matches in the trials.

```{r}
# Reshape the data
reshaped_data <- analogy_data %>%
  select(qualtrics_id, trial_number, response_type) %>%
  pivot_wider(names_from = trial_number, values_from = response_type, names_prefix = "Trial_")

# Check the reshaped data
head(reshaped_data)
```

# Weekly Assignment 4


```{r}
library(dplyr)

data <- read.csv("WeeklyAssignments\\tidy_data\\MFIndD_REI.csv")  

# Preview the data
head(data)

# Check column types
str(data$response)
str(data$scored_response)
```
The "response" column is of type character while the "scored_respose" column is a numeric(int) type.The response column contains the actual survey responses which is not inherently numeric, so it is stored as a character or factor type. The scored_response column contains numeric values that have been derived from the responses, specifically designed to quantify the survey responses for analysis.

```{r}

# Convert the response column into numeric values
data <- data %>%
  mutate(response_numeric = as.double(case_when(
    response == "Strongly Disagree" ~ 1,
    response == "Disagree" ~ 2,
    response == "Neutral" ~ 3,
    response == "Agree" ~ 4,
    response == "Strongly Agree" ~ 5,
    TRUE ~ NA_real_  # Handling any unexpected values
  )))

data$response_numeric[is.na(data$response_numeric)] <- as.double(data$response[is.na(data$response_numeric)])

head(data)
```


```{r}
data <- data %>%
  mutate(new_scored_response = case_when(
    is.na(rev_scoring) ~ response_numeric,
    TRUE ~ 6 - response_numeric  # Reverse scoring logic
  ))

head(data)
```



```{r}
# Compare new_scored_response with scored_response
comparison <- data %>%
  select(new_scored_response, scored_response) %>%
  mutate(match = new_scored_response == scored_response)

# Summary of matches
match_summary <- comparison %>%
  summarise(
    total_rows = n(),
    matches = sum(match, na.rm = TRUE),
    mismatch_count = total_rows - matches
  )

print(match_summary)
```
# Weekly Assignment 5
```{r}
library(dplyr)
library(readr)

# Read the dataset
data <- read_csv("WeeklyAssignments/tidy_data/MFIndD_REI.csv")

# Create a new column for reverse scoring
data <- data %>%
  mutate(new_scored_response = case_when(
    is.na(rev_scoring) ~ scored_response,
    TRUE ~ 6 - scored_response  # Reverse scoring logic
  ))

# Summarize the data to get one row per participant and sub_scale
summary_data2 <- data %>%
  group_by(qualtrics_id, sub_type) %>%  # Group by participant and sub_scale
  summarise(score = sum(new_scored_response, na.rm = TRUE), .groups = 'drop')

# Preview the summarized data
print(head(summary_data2))



```



```{r}
# Check for NA scores in the summarized data
na_scores <- summary_data2 %>%
  filter(is.na(score))

# Count the number of NA scores
na_count <- nrow(na_scores)

# Output the count of NA scores
na_count

```
The code filters the summary_data for any rows where the score is NA and counts how many such rows exist. Since na_count returns 0, there are no NA scores in the summary.


```{r}
# Summarize the analogy dataset
analogy_summary <- analogy_data %>%
  group_by(qualtrics_id) %>%
  summarize(relational_matches = sum(response_type == "Rel", na.rm = TRUE), .groups = 'drop')

# Combine the two summarized datasets
combined_data <- full_join(summary_data2, analogy_summary, by = "qualtrics_id")

# Preview the combined dataset
print(head(combined_data))



```

```{r}
library(ggplot2)

# Create the scatterplot
ggplot(combined_data, aes(x = score, y = relational_matches, color = sub_type)) +
  geom_point(size = 3, alpha = 0.7) +  # Scatter points
  geom_smooth(method = "lm", se = TRUE, linetype = "dashed", color = "black") +  # Smoothed line
  labs(title = "Relationship Between REI Score and Analogy Score",
       x = "REI Score",
       y = "Analogy Score (Relational Matches)",
       color = "REI Sub-Type") +  # Custom axis labels
  theme_minimal() +  # Clean theme
  theme(panel.grid.major = element_line(color = "lightgray"),  # Change grid line color
        panel.grid.minor = element_blank())  # Remove minor grid lines

```

Based on the plot, I noticed that there is not a strong correlation between the two values as modeled by the best fit function being close to horizontal. Each REI sub-type has more data points with an analogy score of 4 or less except for type EE which has more data points with an analogy score of 6 or more.




# Weekly Assignment 6


```{r}
data <- read_csv("WeeklyAssignments/tidy_data/MFIndD_probtask.csv")

# Get distinct values in the 'condition' column
distinct_conditions_vector <- unique(data$condition)

# Initialize an empty vector for mean reaction times
mean_reaction_times <- numeric(length(distinct_conditions_vector))

# Loop through each distinct condition
for (i in seq_along(distinct_conditions_vector)) {
    condition <- distinct_conditions_vector[i]
    conditionstr=condition
    # Filter the data
    condition_data <- subset(data, data$condition == conditionstr)
    # Calculate the mean reaction time
    mean_rt <- mean(condition_data$rt, na.rm = TRUE)
    mean_reaction_times[i] <- mean_rt
    
    # Print the mean reaction time for each condition
    print(paste("Condition:", condition, "Mean RT:", mean_rt))
}


results <- data.frame(Condition = distinct_conditions_vector, Mean_Reaction_Time = mean_reaction_times)

print(results)




```




```{r}
# Using dplyr with across()
results_across <- data %>%
  group_by(condition) %>%
  summarize(
    Mean_Reaction_Time = mean(rt, na.rm = TRUE),
    Overall_Accuracy = mean(correct, na.rm = TRUE),  
    .groups = 'drop'  
  )

print(results_across)
```


```{r}
# Using dplyr without across()
results_no_across <- data %>%
  group_by(condition) %>%
  summarize(
    Mean_Reaction_Time = mean(rt, na.rm = TRUE),
    Overall_Accuracy = mean(correct, na.rm = TRUE), 
    .groups = 'drop'  
  )

print(results_no_across)
```



# Weekly Assignment 7

```{r}
prob_data <- read_csv("WeeklyAssignments/tidy_data/MFIndD_probtask.csv")

prob_data %>%
group_by(condition) %>%
summarise(across(c(rt, correct), mean)) %>%
pivot_longer(c(rt, correct)) %>%
ggplot(aes(y = value, x = condition)) +
geom_point(color = "red") +
facet_wrap(~name, scales = "free")
```
1a. Based on the plot, people's scores and reaction times are inversely related- with the higher reaction times having a lower score and vice versa. The dots_EqSizeRand image represented this relationship the least.

1b. The first thing I noticed when I looked at the plot was that the data points for 3 of the 4 images were on completely different ends of the y axis when comparing the correctness graph and the reaction time graph. I think this is the case because the longer you take to come up with an answer, the more unsure you are of what the correct answer is. When your able to answer a question quickly, particularly in this sort of task, your level of certainty is generally higher.

1c. The information that is hard to see in this plot is the inverse relation between the people's score and reaction time for the dots_EqSizeRand image- especially when compared to the relations between the two for the other images. I think this is the case because if the relationship between reaction time and correctness followed the same pattern as the other images, this image's reaction time would be a lot less compared to where it is now. I believe this is because it is easier to be correct when the blue and orange points are not separated which is why blob_stacked and dots_EqSizeRand have the highest scores- but the latter takes much more time because there are significantly more data points to account for.

```{r}
summarized_data <- prob_data %>%
  group_by(SubID, condition) %>%
  summarise(prop_corr = mean(correct), .groups = "drop")

# Calculate mean and standard error of proportion correct for each condition
plot_data <- summarized_data %>%
  group_by(condition) %>%
  summarise(
    mean_prop_corr = mean(prop_corr),
    se_prop_corr = sd(prop_corr) / sqrt(n())
  )

# Create a plot with error bars to represent standard error
ggplot(plot_data, aes(x = condition, y = mean_prop_corr)) +
  geom_point(color = "blue", size = 3) +
  geom_errorbar(aes(ymin = mean_prop_corr - se_prop_corr, ymax = mean_prop_corr + se_prop_corr), 
                width = 0.2, color = "blue") +
  labs(x = "Condition", y = "Mean Proportion Correct", title = "Proportion Correct by Condition") +
  theme_minimal()
```

Instead of simply plotting mean values, we calculate prop_corr to represent the proportion of correct trials per participant and condition, which better captures individual performance. Also, adding error bars to the mean proportions conveys the variability in the data, giving viewers a clearer sense of how consistent the accuracy is across participants. This avoids the common issue of plots that misleadingly imply small differences are meaningful without considering variability.


```{r}
summarized_data <- prob_data %>%
  group_by(SubID, condition) %>%
  summarise(prop_corr = mean(correct), .groups = "drop")


plot_data <- summarized_data %>%
  group_by(condition) %>%
  summarise(
    mean_prop_corr = mean(prop_corr),
    se_prop_corr = sd(prop_corr) / sqrt(n())
  )

ggplot(plot_data, aes(x = condition, y = mean_prop_corr)) +
  # Add slab interval to show the distribution of data
  stat_slab(
    aes(dist = "normal", mean = mean_prop_corr, sd = se_prop_corr),
    fill = "skyblue", color = "darkblue", alpha = 0.3
  ) +
  geom_point(color = "blue", size = 3) +
  geom_errorbar(aes(ymin = mean_prop_corr - se_prop_corr, ymax = mean_prop_corr + se_prop_corr), 
                width = 0.2, color = "blue") +
  labs(x = "Condition", y = "Mean Proportion Correct", title = "Proportion Correct by Condition") +
  theme_minimal() +
  # Center title and increase text size for readability
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

The slab provides a shaded area around each condition’s mean, showing the distribution and giving a more complete sense of how individual values vary around the mean. This layer allows us to see if the data distribution is skewed or has outliers, adding depth to our understanding of the data’s spread.